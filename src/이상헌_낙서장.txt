2024/02/21
동영상의 라벨 값들을 Tokenizer()로 토큰화한 뒤 인코딩한 후에 CNN + LSTM을 통해 수어 동영상을 입력받아서
이 수어가 어떤 단어 혹은 어떤 문장인지 텍스트로 예측해주는 모델을 만드려고 했다. 근데 영상의 길이가 다 달라서 같은 timesteps의 image 모음으로 나눌수가 없다. 
그렇게 되면 LSTM을 사용할 방법이 없어져 여러가지 방법을 생각해 봤다.
 1. 데이터 손실이 있더라도 모든 영상의 frame 수를 고정.   ( 영상의 길이가 1초 ~ 30초로 큰 차이를 보이기에 불가능 )
 2. 영상을 길이에 따라 일정한 비율로 나누어 frame 수를 같게한다. ( 마찬가지로 각 영상의 길이 차이가 크면 클 수록 데이터가 이상해진다. 불가능 )
 3. 아직 배운적 없는 트랜스포머 기법을 사용한다. ( 트랜스포머는 입력 시퀀스의 길이에 대해 유연하게 대응할 수 있는 모델입니다.(지피티 피셜) <--- 영상길이가 천차만별이라 고생 중인 우리 팀 에게 필요하다. )
=================================================================================================================================================================================